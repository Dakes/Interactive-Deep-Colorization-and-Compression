# the network architecture is based on:
# GANs for Extreme Learned Image Compression (https://arxiv.org/pdf/1804.02958.pdf)
# High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs (https://arxiv.org/pdf/1711.11585.pdf)
# Perceptual Losses for Real-Time Style Transfer and Super-Resolution (https://arxiv.org/pdf/1603.08155.pdf)

# Loss and Optimizer (AdamOptimizer for both G and D)
setup_optimizer.g_lr = 2E-4
setup_optimizer.d_lr = 2E-4
setup_optimizer.gan_loss = 'least_squares'      # not_saturating least_squares
setup_optimizer.use_lpips = True
setup_optimizer.use_feature_matching = False

# Shared specs (G and D)
shared_specs.epochs = 20
shared_specs.batch_size = 32
shared_specs.k_beta = 1                         # GAN loss scaler
shared_specs.k_m = 10                           # MSE loss scaler (always 0.5)
shared_specs.k_p = 10                           # LPIPS loss scaler (always 0.5)
shared_specs.k_fm = 0.5                         # Feature Matching loss scaler
shared_specs.channel_bottleneck = 8
shared_specs.disc_scale = 1

# I/O and data structure
io.base_path = '/home/kiadmin/projects/Interactive-Deep-Colorization-and-Compression/'
io.ckpt_dir = 'res/out/gen_compression_gray/training_checkpoints'
io.gen_imgs_dir = 'res/out/gen_compression_gray/images/'
io.tb_dir = 'res/out/gen_compression_gray/tensorboard/'
io.model_dir = 'res/out/gen_compression_gray/model/'
io.log_dir = 'res/out/gen_compression_gray/log_dir/'
io.lpips_weights = 'res/out/gen_compression_gray/model/lpips_weights'
io.test_out = '/res/out/test_gray'

# ============================================================
# Dataset (imagenet dataset)
io.input_dim_raw = (256, 256, 1)
io.input_dim_target = (256, 256, 1)
io.buf_size = 90000
io.data = '/imagenet-mini/' # probably not needed, preprocessing is done outside of the compression nets
io.data_test = 'res/test/ground_truth_gray'
